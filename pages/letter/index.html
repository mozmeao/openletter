{% extends "base.html" %}

{% block page_title %}Joint Statement on AI Safety and Openness{% endblock %}
{% block page_desc %}We are at a critical juncture in AI governance. To mitigate current and future harms from AI systems, we need to embrace openness, transparency, and broad access.{% endblock %}
{% block page_image %}/img/social.png{% endblock %}

{% block page_css %}<link rel="stylesheet" href="/css/style.scss">{% endblock %}

{% set share_text = 'The future of #AI governance is here. Join a global community of policymakers, engineers, activists, and more in ensuring that AI remains open and accessible to all. \n\n' | urlencode %}
{% set share_url = 'https://open.mozilla.org/letter/' %}

{% block content %}
<article class="c-letter">
  <header class="c-letter-head c-letter-section mzp-t-background-secondary">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <h1>Joint Statement on AI Safety and Openness</h1>
      <p><time datetime="2023-10-31">October 31, 2023</time></p>
    </div>
  </header>

  <section class="c-letter-body c-letter-section">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <p class="c-letter-intro">We are at a critical juncture in AI governance. To mitigate current and
        future harms from AI systems, we need to embrace openness, transparency,
        and broad access. This needs to be a global priority.</p>

      <p>Yes, openly available models come with risks and vulnerabilities — AI models
        can be abused by malicious actors or deployed by ill-equipped developers.
        However, we have seen time and time again that the same holds true for
        proprietary technologies — and that increasing public access and scrutiny
        makes technology safer, not more dangerous. The idea that tight and proprietary
        control of foundational AI models is the only path to protecting us from
        society-scale harm is naive at best, dangerous at worst.</p>

      <p>Further, history shows us that quickly rushing towards the wrong kind of
        regulation can lead to concentrations of power in ways that hurt competition
        and innovation. Open models can inform an open debate and improve policy
        making. If our objectives are safety, security and accountability, then
        openness and transparency are essential ingredients to get us there.</p>

      <p>We are in the midst of a dynamic discourse about what 'open' signifies in
        the AI era. This important debate should not slow us down. Rather, it should
        speed us up, encouraging us to experiment, learn and develop new ways to
        leverage openness in a race to AI safety.</p>

      <p>We need to invest in a spectrum of approaches — from open source to open
        science — that can serve as the bedrock for:</p>

      <ol class="mzp-u-list-styled u-list-type-upper-alpha" type="A">
        <li>Accelerating the understanding of AI capabilities risks and harms by
          enabling independent research, collaboration and knowledge sharing.</li>
        <li>Increasing public scrutiny and accountability by helping regulators adopt
          tools to monitor large scale AI systems.</li>
        <li>Lowering the barriers to entry for new players focused on creating
          responsible AI.</li>
      </ol>

      <p>As signatories to this letter, we are a diverse group — scientists, policymakers,
        engineers, activists, entrepreneurs, educators and journalists. We represent
        different, and sometimes divergent, perspectives, including different views
        on how open source AI should be managed and released. However, there is one
        thing we strongly agree on: open, responsible and transparent approaches
        will be critical to keeping us safe and secure in the AI era.</p>

      <p>When it comes to AI safety and security, openness is an antidote, not a poison.</p>

      <aside class="c-share">
        <button class="mzp-c-button mzp-t-secondary mzp-t-sm js-mastodon-share"
          data-share-url="{{ share_url }}"
          data-share-text="{{ share_text }}">
          Share on Mastodon
        </button>

        <a href="https://twitter.com/intent/tweet/?text={{ share_text }}&amp;url={{ share_url }}&amp;via=mozilla"
          rel="external nofollow noopener" target="_blank"
          class="mzp-c-button mzp-t-secondary mzp-t-sm">
          Share on X
        </a>
      </aside>
    </div>
  </section>

  <section id="sign" class="c-letter-form c-letter-section mzp-t-background-secondary">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <form name="signatures" id="signature-form" class="mzp-c-form" method="post">
        <fieldset>
          <div class="mzp-c-form-header">
            <h2 class="mzp-c-form-title">Add your signature</h2>
          </div>

          <div class="mzp-c-form-errors hidden" id="letter-errors">
            <ul class="mzp-u-list-styled">
              <li class="error-email-invalid hidden">Please enter a valid email address with less than 120 characters</li>
              <li class="error-try-again-later hidden">We are sorry, but there was a problem with our system. Please try again later!</li>
            </ul>
          </div>

          <div class="mzp-l-columns mzp-t-columns-two">
            <div class="col">
              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="name">Your full name</label>
                <input class="mzp-c-field-control" type="text" name="name" id="name" value="" required aria-required="true">
              </div>

              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="email">Email address (professional)</label>
                <input class="mzp-c-field-control mzp-js-email-field" type="email" name="email" id="email" value="" placeholder="name@example.com" required aria-required="true">
              </div>
            </div>

            <div class="col">
              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="title">Job title</label>
                <input class="mzp-c-field-control" type="text" name="title" id="title" value="">
              </div>

              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="affiliation">Affiliation</label>
                <input class="mzp-c-field-control" type="text" name="affiliation" id="affiliation" value="" required aria-required="true">
              </div>
            </div>
          </div>

          <div class="mzp-c-button-container mzp-l-align-center mzp-l-stretch">
            <p class="mzp-c-button-info">
              By submitting this form you agree to Mozilla handling your information
              as explained in <a href="https://www.mozilla.org/privacy/websites/" target="_blank">this privacy notice</a>.
            </p>

            <button class="mzp-c-button mzp-t-xl" type="submit">Sign the letter</button>
          </div>
        </fieldset>
      </form>

      <div id="signature-thanks" class="c-letter-thanks hidden">
        <h3>Thanks!</h3>
        <p>Thank you for lending your voice to this initiative. Check your email for a confirmation. Once confirmed we’ll add your name to the list of signatories.</p>
      </div>
    </div>
  </section>

  <section id="signatures" class="c-letter-signatures c-letter-section">
    <div class="mzp-l-content mzp-t-content-xl mzp-t-content-nospace">
      <header>
        <aside class="c-signature-count">
          <strong>{{ signatures.length }}</strong> signatures
        </aside>

        <h2 class="c-signatures-title mzp-u-title-sm">Signatories<span>(in order of signing)</span></h2>
      </header>

      <ol class="c-signatures-list" role="list">
      {% for sig in signatures %}
        <li><cite>{{ sig.name }}</cite>{% if sig.affiliation %}, {{ sig.affiliation }}{% endif %}</li>
      {% endfor %}
      </ol>

    </div>
  </section>
</article>
{% endblock %}

{% block js %}
  <script src="/scripts/mastodon.js"></script>
  <script src="/scripts/email.js"></script>
{% endblock %}
