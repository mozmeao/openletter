{% extends "base.html" %}

{% block page_title %}Joint Statement on AI Safety and Openness{% endblock %}

{% block page_desc %}We are at a critical juncture in AI governance. To mitigate current and future harms from AI systems, we need to embrace openness, transparency, and broad access.{% endblock %}

{% block page_css %}<link rel="stylesheet" href="/css/style.scss">{% endblock %}

{% block content %}
<article class="c-letter">
  <header class="c-letter-head c-letter-section mzp-t-background-secondary">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <div class="mzp-c-wordmark mzp-t-wordmark-sm mzp-t-product-mozilla">Mozilla</div>

      <h1>Joint Statement on AI Safety and Openness</h1>
      <p><time datetime="2023-10-31">October 31, 2023</time></p>
    </div>
  </header>

  <section class="c-letter-body c-letter-section">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <p class="c-letter-intro">We are at a critical juncture in AI governance. To mitigate current and
        future harms from AI systems, we need to embrace openness, transparency,
        and broad access. This needs to be a global priority.</p>

      <p>Yes, openly available models come with risks and vulnerabilities — AI models
        can be abused by malicious actors or deployed by ill-equipped developers.
        However, we have seen time and time again that the same holds true for
        proprietary technologies — and that increasing public access and scrutiny
        makes technology safer, not more dangerous. The idea that tight and proprietary
        control of foundational AI models is the only path to protecting us from
        society-scale harm is naive at best, dangerous at worst.</p>

      <p>Further, history shows us that quickly rushing towards the wrong kind of
        regulation can lead to concentrations of power in ways that hurt competition
        and innovation. Open models can inform an open debate and improve policy
        making. If our objectives are safety, security and accountability, then
        openness and transparency are essential ingredients to get us there.</p>

      <p>We are in the midst of a dynamic discourse about what 'open' signifies in
        the AI era. This important debate should not slow us down. Rather, it should
        speed us up, encouraging us to experiment, learn and develop new ways to
        leverage openness in a race to AI safety.</p>

      <p>We need to invest in a spectrum of approaches — from open source to open
        science — that can serve as the bedrock for:</p>

      <ol class="mzp-u-list-styled u-list-type-upper-alpha" type="A">
        <li>Accelerating the understanding of AI capabilities risks and harms by
          enabling independent research, collaboration and knowledge sharing.</li>
        <li>Increasing public scrutiny and accountability by helping regulators adopt
          tools to monitor large scale AI systems.</li>
        <li>Lowering the barriers to entry for new players focused on creating
          responsible AI.</li>
      </ol>

      <p>As signatories to this letter, we are a diverse group — scientists, policymakers,
        engineers, activists, entrepreneurs, educators and journalists. We represent
        different, and sometimes divergent, perspectives. However, there is one thing
        we strongly agree on: open, responsible and transparent approaches will be
        critical to keeping us safe and secure in the AI era.</p>

      <p>When it comes to AI safety and security, openness is an antidote, not a poison.</p>
    </div>
  </section>

  <section id="sign" class="c-letter-form c-letter-section mzp-t-background-secondary">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <form class="mzp-c-form" method="post" action="#" data-netlify="true">
        <fieldset>
          <div class="mzp-c-form-header">
            <h2 class="mzp-c-form-title">Add your signature</h2>
          </div>

          <div class="mzp-l-columns mzp-t-columns-two">
            <div class="col">
              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="name">Your full name</label>
                <input class="mzp-c-field-control" type="text" name="name" id="name" value="" required>
              </div>

              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="email">Email address (professional)</label>
                <input class="mzp-c-field-control" type="email" name="email" id="email" value="" placeholder="name@example.com" required>
              </div>
            </div>

            <div class="col">
              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="title">Job title</label>
                <input class="mzp-c-field-control" type="text" name="title" id="title" value="">
              </div>

              <div class="mzp-c-field">
                <label class="mzp-c-field-label" for="affiliation">Affiliation</label>
                <input class="mzp-c-field-control" type="text" name="affiliation" id="affiliation" value="" required>
              </div>
            </div>
          </div>

          <div class="mzp-c-button-container mzp-l-align-center mzp-l-stretch">
            <p class="mzp-c-button-info">
              By submitting this form you agree to Mozilla handling your information
              as explained in <a href="https://www.mozilla.org/privacy/websites/" target="_blank">this privacy notice</a>.
            </p>

            <button class="mzp-c-button mzp-t-xl" type="submit">Sign the letter</button>
          </div>
        </fieldset>
      </form>
    </div>
  </section>

  <section id="signatures" class="c-letter-signatures c-letter-section">
    <div class="mzp-l-content mzp-t-content-md mzp-t-content-nospace">
      <div class="c-signatures-inner">
        <aside class="c-signature-count">
          <strong>63</strong> signatures
        </aside>

        <div class="c-signatures-list">
          <h2 class="mzp-u-title-sm">Signatories<span>(in order of signing)</span></h2>
          <ol>
            <li><cite>Camille Francois</cite>, Columbia University</li>
            <li><cite>Mark Surman</cite>, Mozilla</li>
            <li><cite>Deborah Raji</cite>, UC Berkeley</li>
            <li><cite>Maria Ressa</cite>, Rappler, Nobel Peace Prize Laureate</li>
            <li><cite>Stella Biderman</cite>, EleutherAI</li>
            <li><cite>Alondra Nelson</cite>, Institute for Advanced Study</li>
            <li><cite>Arthur Mensch</cite>, MistralAI</li>
            <li><cite>Marietje Schaake</cite>, Stanford University</li>
            <li><cite>Abeba Birhane</cite>, Mozilla Fellow</li>
            <li><cite>Bruce Schneier</cite>, Berkman Center</li>
            <li><cite>Mitchell Baker</cite>, Mozilla</li>
            <li><cite>Cedric O</cite>, MistralAI</li>
            <li><cite>Andrew Ng</cite>, AI Fund</li>
            <li><cite>Yann Lecun</cite>, Meta</li>
            <li><cite>Amba Kak</cite>, AI Now</li>
            <li><cite>Joy Buolamwini</cite>, Algorithmic Justice League</li>
            <li><cite>Julien Chaumon</cite>, Hugging Face</li>
            <li><cite>Brian Behlendorf</cite>, Linux Foundation</li>
            <li><cite>Moez Draief</cite>, Mozilla.ai</li>
            <li><cite>Pelonomi Moiloa</cite>, LelapaAI</li>
            <li><cite>Audrey Tang</cite>, Minister of Digital Affairs, Taiwan</li>
            <li><cite>Jimmy Wales</cite>, Wikimedia Foundation</li>
            <li><cite>Krishna Gade</cite>, Fiddler AI</li>
            <li><cite>John Borthwick</cite>, Betaworks</li>
            <li><cite>Karim Lakhani</cite>, Harvard Business School</li>
            <li><cite>Stefano Maffulli</cite>, Open Source Initiative</li>
            <li><cite>Arvind Narayanan</cite>, Princeton University</li>
            <li><cite>Aviya Skowron</cite>, EleutherAI</li>
            <li><cite>Catherine Stihler</cite>, Creative Commons</li>
            <li><cite>Nabiha Syed</cite>, The Markup</li>
            <li><cite>Tim O’Reilly</cite>, O'Reilly Media</li>
            <li><cite>Nicole Wong</cite>, Former Deputy U.S. Chief Technology Officer</li>
            <li><cite>Irina Rish</cite>, Mila - Quebec AI Institute</li>
            <li><cite>Mohamed Nanabhay</cite>, Mozilla Ventures</li>
            <li><cite>Imo Udom</cite>, Mozilla</li>
            <li><cite>Ayah Bdeir</cite>, Mozilla</li>
            <li><cite>Blake Richards</cite>, McGill/Mila</li>
            <li><cite>Andrea Renda</cite>, CEPS</li>
            <li><cite>Jenia Jitsev</cite>, LAION</li>
            <li><cite>Charles Gorintin</cite>, MistralAI</li>
            <li><cite>Daniel J. Beutel</cite>, Flower Labs</li>
            <li><cite>Nicholas Lane</cite>, Flower Labs</li>
            <li><cite>Taner Topal</cite>, Flower Labs</li>
            <li><cite>Aaron Gokaslan</cite>, Cornell University</li>
            <li><cite>Shayne Longpre</cite>, MIT</li>
            <li><cite>Luca Soldaini</cite>, Allen Institute for AI</li>
            <li><cite>Joelle Pineau</cite>, Meta</li>
            <li><cite>Michiel van de Panne</cite>, University of British Columbia</li>
            <li><cite>Nawar Alsafar</cite>, Bytez Inc</li>
            <li><cite>Holly Peck</cite>, Bytez Inc</li>
            <li><cite>Susan Hendrickson</cite>, Harvard University</li>
            <li><cite>Sharad Sharma</cite>, iSPIRT Foundation</li>
            <li><cite>Andy Stepanian</cite>, The Sparrow Project</li>
            <li><cite>Paul Keller</cite>, Open Future</li>
            <li><cite>Goran Marby</cite>, Ybram Consulting</li>
            <li><cite>Huu Nguyen</cite>, Ontocord.ai; LAION.ai</li>
            <li><cite>Mike Bracken</cite>, Public Digital</li>
            <li><cite>Elaheh Ahmadi</cite>, Themis AI</li>
            <li><cite>Umakant Soni</cite>, AI Foundry, ART Venture Fund</li>
            <li><cite>Saoud Khalifah</cite>, Mozilla</li>
            <li><cite>Irene Solaiman</cite>, Hugging Face</li>
            <li><cite>Merouane Debbah</cite>, Khalifah University</li>
            <li><cite>Felix Reda</cite>, Former Member of the European Parliament</li>
          </ol>
        </div>
      </div>
    </div>
  </section>
</article>
{% endblock %}
